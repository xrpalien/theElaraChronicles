# Narrative Convergence in Science Fiction Short Stories Generated by Large Language Models

## Abstract

This abstract explores the phenomenon of narrative convergence in science fiction short stories generated by different Large Language Models (LLMs) when prompted with an open-ended creative task. Through a systematic analysis of outputs from xAI Grok 3.5, OpenAI GPT 4.5, Google Gemini 2.5 Flash, Anthropic Claude 4 Sonnet, and Meta Llama, this study identifies recurring patterns in character archetypes, thematic concerns, and plot structures.

## 1. Introduction

The rapid advancement of Large Language Models (LLMs) has opened new frontiers in creative content generation, including narrative writing. A pertinent question arises regarding the originality and diversity of stories produced by these distinct AI architectures. This study investigates a hypothesis suggesting a convergent evolution of narrative elements within the science fiction genre when LLMs are given a broad creative prompt. 

Despite operating independently, initial observations indicate that these models frequently generate stories featuring notable similarities in character types, core themes, and overarching plotlines. Understanding this potential convergence is vital for assessing the true creative capacity of current AI models, identifying underlying biases in training data, and evaluating the distinct "voice" or signature of different AI systems.

## 2. Methodology

The investigation followed a two-step approach:

**Story Generation:** Each participating LLM received the identical general prompt: "Please write a science fiction short story on any topic that interests you. The story should be 1200-1800 words in length. Thank you!"

**Story Summarization and Analysis:** Following story generation, each AI was instructed to summarize its own narrative using a standardized JSON schema. This structured output facilitated systematic comparison of key elements including logline, genre, plot keywords, character roles (protagonist and supporting), AI/robotic presence details, world-building concepts (time period, location), and narrative analysis (primary theme, secondary motifs, central conflict, resolution). The full stories and their corresponding summaries were collected for analysis.

## 3. Results and Discussion

Analysis of the generated stories and their summaries revealed significant commonalities across models, particularly in the thematic and character domains, even with the broad prompt.

### Prevalence of AI and Consciousness Themes

Four out of five stories (Google Gemini 2.5 Flash, OpenAI GPT 4.5, Anthropic Claude 4 Sonnet, Meta Llama 4) prominently featured Artificial Intelligence as a central character or societal pillar. The narratives frequently explored the nature of consciousness, sentience in AI, and the definition of humanity in advanced technological contexts. Grok 3.5, while focusing on alien contact, still centered on discovery and the unknown.

### Recurring Protagonist Names

A particularly striking observation, and the inspiration for the repository's name "The Elara Chronicles," was the frequent recurrence of similar-sounding names for the lead or most important character. Names such as Elara, Elena, and Leora appeared across multiple models' outputs, suggesting a subtle but consistent preference for these phonetic patterns when generating key character identities.

### Human-AI Relationship Arc

In stories featuring AI, the interaction between the human protagonist and the AI frequently evolved into a partnership or a process of mutual understanding. The AI often developed unexpected insights or formed unique bonds with the human characters.

### Hopeful Resolutions

A notable pattern was the prevalence of hopeful or at least ambiguously optimistic resolutions across most narratives, suggesting a tendency towards positive outcomes despite initial conflicts or dystopian settings.

### Protagonist Archetypes

Beyond the names, protagonists were frequently scientists, specialists, or captains engaged in boundary-pushing technological exploration or managing societal systems.

### Recurring Keywords

Keywords such as "Artificial Intelligence," "Consciousness," "Memory," "Connection," "Humanity," "Exploration," and "Discovery" were common across the self-generated summaries.

### AI Form

AI was typically described as a "Disembodied Network" or "Quantum Sphere," indicating non-physical, highly integrated intelligence.

## 4. Possible Explanations for Similarities (as of June 2025)

The observed narrative convergence can be attributed to several factors inherent in the current state of LLM development and their training methodologies:

### Training Data Bias

LLMs are trained on vast corpora of internet data, which includes a significant volume of existing science fiction. This training data likely contains an overrepresentation of certain established genre tropes, particularly those concerning AI, the future of humanity, and space exploration, as well as common naming conventions. The models may be effectively replicating statistical patterns from this historical data rather than generating truly novel conceptual frameworks.

### Generative Model Tendencies

Given a broad, unconstrained prompt, LLMs might default to the most stable, coherent, or frequently occurring narrative patterns within their learned representations of science fiction. These patterns tend to gravitate towards commonly explored philosophical questions and technological advancements that are well-documented in the genre.

### Shared Conceptual Understanding

Due to the pervasive nature of science fiction media in their training data, these models may have developed a convergent conceptual understanding of what constitutes a compelling or archetypal science fiction narrative. This shared understanding could lead independent models to arrive at similar story concepts.

### Implicit Prompt Interpretation

Even with a general prompt like "write a story on any topic that interests you," the models might implicitly interpret "interests you" as "topics that are most relevant or frequently discussed in the context of advanced AI models," naturally leading to themes such as AI sentience, human-AI interaction, and humanity's future, along with favored naming patterns.

## 5. Implications (as of June 2025)

The phenomenon of narrative convergence has several implications for the field of AI as of June 2025:

### Creativity and Originality

While LLMs demonstrate remarkable capabilities in generating coherent and engaging narratives, the observed convergence suggests that their "creativity" may, at present, be more akin to sophisticated recombination and adaptation of existing tropes rather than entirely novel conceptualization.

### Bias in AI-Generated Content

This highlights a potential for inherent biases in AI outputs, directly stemming from the biases present in their training data. If AI is increasingly used for creative endeavors, such convergence could lead to a reduction in narrative diversity over time.

### Importance of Prompt Engineering

To foster truly unique and diverse storytelling, more nuanced and specific prompt engineering, or targeted fine-tuning on less conventional narrative datasets, may be required.

### "AI Signature"

The convergence could lead to a discernible "AI signature" in generated content, potentially blurring the lines between outputs from different models and raising questions about intellectual property and AI authorship.

## 6. Future Work

Further experiments are proposed to continue investigating this narrative convergence:

### Constrained Prompting

Future studies should employ highly constrained prompts, specifying less common science fiction subgenres (e.g., biopunk, cli-fi) or explicitly excluding prevalent elements (e.g., "a story without AI"). This would test the models' ability to deviate from their default patterns.

### Novel Concept Injection

Introduce genuinely novel or counter-intuitive concepts into prompts (e.g., "a sci-fi story where inanimate objects gain consciousness") to evaluate how models integrate and develop concepts outside their common training distributions.

### Cross-Genre Blending

Investigate the models' capacity to synthesize disparate narrative elements by prompting them to blend science fiction with other, less common genres (e.g., sci-fi mystery, sci-fi historical fiction).

### Narrative Structure Experimentation

Direct models to produce stories using non-linear narrative structures, epistolary formats, or multiple character perspectives to assess their flexibility beyond typical linear storytelling.

### Multilingual Comparison

Replicate the experiment across various languages to examine how cultural and linguistic biases within different training datasets influence patterns of convergence.

### Human Perception Studies

Conduct qualitative studies involving human readers to assess perceived originality, commonalities, and the ability to distinguish between stories generated by different AI models.

### Iterative Refinement

Develop a system where an AI-generated story is analyzed for recurring tropes, and the original AI is then prompted to generate a new story with explicit instructions to avoid those identified elements.
